{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KPmUEiDU7rZ"
      },
      "source": [
        "# Downloading Data / Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq6LpnkmvOBq",
        "outputId": "ce9c3cbc-e05a-433f-d777-3b8f892f249a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4su2vqTv8ep",
        "outputId": "62994b0d-43e0-4e96-8890-b4ee1756c3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TXMXE1V20I88"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T6wk8CKj10T2"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/kaggle_api_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IEOsIdUo208p"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaufNfIP3kvU",
        "outputId": "c5f2e1e8-70c0-4901-8fb2-5c7223e3e35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 77% 221M/285M [00:00<00:00, 772MB/s] \n",
            "100% 285M/285M [00:00<00:00, 375MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download challenges-in-representation-learning-facial-expression-recognition-challenge --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q57Qk0Ww9ZFy",
        "outputId": "e3dd5b31-9730-4ce2-e7bd-7ec67e5ac38d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 286M\n",
            "-rw-r--r-- 1 root root 286M Dec 11  2019 challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "drwx------ 6 root root 4.0K Jun  5 13:58 drive\n",
            "drwxr-xr-x 1 root root 4.0K Jun  3 14:04 sample_data\n",
            "drwxr-xr-x 4 root root 4.0K Jun  5 13:57 wandb\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vb3YNjA-nv2",
        "outputId": "6358f371-8a8f-4a06-d83d-bbf991608ae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF-EeCU-CEXm"
      },
      "source": [
        "# Set up Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "q-TUAsoMCIO3"
      },
      "outputs": [],
      "source": [
        "!pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_iJer9FF7YC",
        "outputId": "4aacf243-63ab-4954-9659-172948988525"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "YsUyaO-7Gs7u",
        "outputId": "963471dd-12b3-462d-db3e-6f6c8e4d54e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-totem-4</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/3ioiae4q' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/3ioiae4q</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_135717-3ioiae4q/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_135938-zl9j1cyl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">breezy-glitter-3</a></strong> to <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▁▆▇▄▆█</td></tr><tr><td>loss</td><td>█▄▂▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.84463</td></tr><tr><td>loss</td><td>0.2518</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">breezy-glitter-3</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_135938-zl9j1cyl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import wandb\n",
        "\n",
        "# Start a new wandb run to track this script.\n",
        "run = wandb.init(\n",
        "    # Set the wandb entity where your project will be logged (generally your team name).\n",
        "    entity=\"ashar-22-free-university-of-tbilisi-\",\n",
        "    # Set the wandb project where this run will be logged.\n",
        "    project=\"setup\",\n",
        "    # Track hyperparameters and run metadata.\n",
        "    config={\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"architecture\": \"CNN\",\n",
        "        \"dataset\": \"CIFAR-100\",\n",
        "        \"epochs\": 10,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Simulate training.\n",
        "epochs = 10\n",
        "offset = random.random() / 5\n",
        "for epoch in range(2, epochs):\n",
        "    acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
        "    loss = 2**-epoch + random.random() / epoch + offset\n",
        "\n",
        "    # Log metrics to wandb.\n",
        "    run.log({\"acc\": acc, \"loss\": loss})\n",
        "\n",
        "# Finish the run and upload any remaining data.\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWpIOcf5CuYb"
      },
      "source": [
        "# Handling Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWgiJYh_NzS7"
      },
      "outputs": [],
      "source": [
        "# utils/data.py\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "from PIL import Image\n",
        "\n",
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = np.array(self.data.iloc[idx]['pixels'].split(), dtype='uint8').reshape(48, 48)\n",
        "        image = Image.fromarray(pixels)  # PIL Image\n",
        "        label = int(self.data.iloc[idx]['emotion']) if 'emotion' in self.data.columns else -1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_data_loaders(csv_path, batch_size=64):\n",
        "    # Define transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.RandomResizedCrop(48, scale=(0.8, 1.0)),\n",
        "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    val_test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Load the full dataset without a transform initially\n",
        "    dataset = FER2013Dataset(csv_file=csv_path, transform=None)\n",
        "\n",
        "    # Split into train/val/test\n",
        "    train_len = int(0.7 * len(dataset))\n",
        "    val_len = int(0.15 * len(dataset))\n",
        "    test_len = len(dataset) - train_len - val_len\n",
        "    train_data, val_data, test_data = random_split(dataset, [train_len, val_len, test_len])\n",
        "\n",
        "    # Manually assign transforms to each subset\n",
        "    train_data.dataset.transform = train_transform\n",
        "    val_data.dataset.transform = val_test_transform\n",
        "    test_data.dataset.transform = val_test_transform\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdjP6D2qDA2u"
      },
      "source": [
        "# Adding Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "uIBDCBYIYi5g"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(512 * 1 * 1, 256)\n",
        "        self.fc2 = nn.Linear(256, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # 48 -> 24\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # 24 -> 12\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # 12 -> 6\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))  # 6 -> 3\n",
        "        x = self.pool(F.relu(self.bn5(self.conv5(x))))  # 3 -> 1\n",
        "        x = x.view(-1, 512 * 1 * 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRQxPaNiDFsK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PCydxf1nOdGS",
        "outputId": "a666b498-5d73-4d4f-a400-4009ce7df237"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_165729-kogdfq5b</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/kogdfq5b' target=\"_blank\">run_4_deep_cnn</a></strong> to <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/kogdfq5b' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/kogdfq5b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging: train_acc=0.3338972929936306, val_acc=0.39526242452392013, lr=0.001\n",
            "Epoch 1/10 | Train Loss: 1.6609, Train Acc: 0.3339 | Val Loss: 1.5581, Val Acc: 0.3953\n",
            "Logging: train_acc=0.4557125796178344, val_acc=0.4633070134695773, lr=0.0009755282581475768\n",
            "Epoch 2/10 | Train Loss: 1.4136, Train Acc: 0.4557 | Val Loss: 1.4141, Val Acc: 0.4633\n",
            "Logging: train_acc=0.518312101910828, val_acc=0.5134695773339526, lr=0.0009045084971874736\n",
            "Epoch 3/10 | Train Loss: 1.2622, Train Acc: 0.5183 | Val Loss: 1.2871, Val Acc: 0.5135\n",
            "Logging: train_acc=0.5774283439490446, val_acc=0.5281003251277288, lr=0.0007938926261462366\n",
            "Epoch 4/10 | Train Loss: 1.1307, Train Acc: 0.5774 | Val Loss: 1.2473, Val Acc: 0.5281\n",
            "Logging: train_acc=0.637937898089172, val_acc=0.5141662796098467, lr=0.0006545084971874737\n",
            "Epoch 5/10 | Train Loss: 0.9899, Train Acc: 0.6379 | Val Loss: 1.2710, Val Acc: 0.5142\n",
            "Logging: train_acc=0.6924761146496815, val_acc=0.5366929865304226, lr=0.0005\n",
            "Epoch 6/10 | Train Loss: 0.8397, Train Acc: 0.6925 | Val Loss: 1.2836, Val Acc: 0.5367\n",
            "Logging: train_acc=0.7606986464968153, val_acc=0.5118439386901997, lr=0.00034549150281252633\n",
            "Epoch 7/10 | Train Loss: 0.6828, Train Acc: 0.7607 | Val Loss: 1.3645, Val Acc: 0.5118\n",
            "Logging: train_acc=0.8213077229299363, val_acc=0.5473757547607989, lr=0.0002061073738537635\n",
            "Epoch 8/10 | Train Loss: 0.5362, Train Acc: 0.8213 | Val Loss: 1.2475, Val Acc: 0.5474\n",
            "Logging: train_acc=0.8646994426751592, val_acc=0.5578262888992104, lr=9.549150281252634e-05\n",
            "Epoch 9/10 | Train Loss: 0.4392, Train Acc: 0.8647 | Val Loss: 1.2605, Val Acc: 0.5578\n",
            "Logging: train_acc=0.8866441082802548, val_acc=0.5566651184393869, lr=2.4471741852423235e-05\n",
            "Epoch 10/10 | Train Loss: 0.3912, Train Acc: 0.8866 | Val Loss: 1.2584, Val Acc: 0.5567\n",
            "\n",
            "✅ Final Test Loss: 1.2310, Test Accuracy: 0.5853\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>██▇▇▆▄▃▂▂▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▃▃▄▅▆▆▇██</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▃▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▆▇▆███</td></tr><tr><td>val_loss</td><td>█▅▂▁▂▂▄▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>test_accuracy</td><td>0.58533</td></tr><tr><td>test_loss</td><td>1.23098</td></tr><tr><td>train_accuracy</td><td>0.88664</td></tr><tr><td>train_loss</td><td>0.39125</td></tr><tr><td>val_accuracy</td><td>0.55667</td></tr><tr><td>val_loss</td><td>1.25837</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run_4_deep_cnn</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/kogdfq5b' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/kogdfq5b</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_165729-kogdfq5b/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# train.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "\n",
        "def train_and_validate(csv_path, batch_size=64, lr=0.001, epochs=10):\n",
        "    wandb.init(project=\"facial-expression\", name=\"run_4_deep_cnn\", config={\n",
        "        \"model_name\" : \"DeepCNN\",\n",
        "        \"batch_size\": batch_size,\n",
        "        \"lr\": lr,\n",
        "        \"epochs\": epochs\n",
        "    }, reinit=True)\n",
        "\n",
        "    wandb.config.update({\n",
        "    \"optimizer\": \"SGD with momentum\",\n",
        "    \"scheduler\": \"CosineAnnealingLR\",\n",
        "    \"regularization\": \"Dropout + L2\",\n",
        "    \"data_augmentation\": \"flip, rotate, crop, color jitter\"\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        config = wandb.config\n",
        "\n",
        "        train_loader, val_loader, test_loader = get_data_loaders(csv_path, config.batch_size)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = DeepCNN().to(device)\n",
        "        wandb.watch(model, log=\"all\", log_freq=10)  # logs gradients and parameters\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        for epoch in range(config.epochs):\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss = 0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            train_loss_avg = train_loss / len(train_loader)\n",
        "            train_acc = correct / total\n",
        "            val_loss_avg = val_loss / len(val_loader)\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            # print(f\"Logging: train_acc={train_acc}, val_acc={val_acc}, lr={scheduler.get_last_lr()[0]}\")\n",
        "\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"train_loss\": train_loss_avg,\n",
        "                \"train_accuracy\": train_acc,\n",
        "                \"val_loss\": val_loss_avg,\n",
        "                \"val_accuracy\": val_acc,\n",
        "                \"learning_rate\": scheduler.get_last_lr()[0]\n",
        "            })\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{config.epochs} | \"\n",
        "                  f\"Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "                  f\"Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "            scheduler.step()\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loss_avg = test_loss / len(test_loader)\n",
        "        test_acc = test_correct / test_total\n",
        "\n",
        "        print(f\"\\n✅ Final Test Loss: {test_loss_avg:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "        wandb.log({\n",
        "            \"test_loss\": test_loss_avg,\n",
        "            \"test_accuracy\": test_acc\n",
        "        })\n",
        "\n",
        "        # Save model\n",
        "        torch.save(model.state_dict(), \"model.pth\")\n",
        "        wandb.save(\"model.pth\")  # optional but recommended\n",
        "        artifact = wandb.Artifact('facial-expression-model', type='model')\n",
        "        artifact.add_file('model.pth')\n",
        "        wandb.log_artifact(artifact)\n",
        "    finally:\n",
        "        wandb.finish()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_validate(\"train.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
