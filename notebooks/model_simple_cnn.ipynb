{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KPmUEiDU7rZ"
      },
      "source": [
        "# Downloading Data / Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq6LpnkmvOBq",
        "outputId": "ce9c3cbc-e05a-433f-d777-3b8f892f249a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4su2vqTv8ep",
        "outputId": "62994b0d-43e0-4e96-8890-b4ee1756c3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TXMXE1V20I88"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T6wk8CKj10T2"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/kaggle_api_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IEOsIdUo208p"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaufNfIP3kvU",
        "outputId": "c5f2e1e8-70c0-4901-8fb2-5c7223e3e35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 77% 221M/285M [00:00<00:00, 772MB/s] \n",
            "100% 285M/285M [00:00<00:00, 375MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download challenges-in-representation-learning-facial-expression-recognition-challenge --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q57Qk0Ww9ZFy",
        "outputId": "e3dd5b31-9730-4ce2-e7bd-7ec67e5ac38d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 286M\n",
            "-rw-r--r-- 1 root root 286M Dec 11  2019 challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "drwx------ 6 root root 4.0K Jun  5 13:58 drive\n",
            "drwxr-xr-x 1 root root 4.0K Jun  3 14:04 sample_data\n",
            "drwxr-xr-x 4 root root 4.0K Jun  5 13:57 wandb\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vb3YNjA-nv2",
        "outputId": "6358f371-8a8f-4a06-d83d-bbf991608ae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF-EeCU-CEXm"
      },
      "source": [
        "# Set up Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "q-TUAsoMCIO3"
      },
      "outputs": [],
      "source": [
        "!pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_iJer9FF7YC",
        "outputId": "4aacf243-63ab-4954-9659-172948988525"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "YsUyaO-7Gs7u",
        "outputId": "963471dd-12b3-462d-db3e-6f6c8e4d54e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-totem-4</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/3ioiae4q' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/3ioiae4q</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_135717-3ioiae4q/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_135938-zl9j1cyl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">breezy-glitter-3</a></strong> to <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▁▆▇▄▆█</td></tr><tr><td>loss</td><td>█▄▂▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.84463</td></tr><tr><td>loss</td><td>0.2518</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">breezy-glitter-3</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_135938-zl9j1cyl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import wandb\n",
        "\n",
        "# Start a new wandb run to track this script.\n",
        "run = wandb.init(\n",
        "    # Set the wandb entity where your project will be logged (generally your team name).\n",
        "    entity=\"ashar-22-free-university-of-tbilisi-\",\n",
        "    # Set the wandb project where this run will be logged.\n",
        "    project=\"setup\",\n",
        "    # Track hyperparameters and run metadata.\n",
        "    config={\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"architecture\": \"CNN\",\n",
        "        \"dataset\": \"CIFAR-100\",\n",
        "        \"epochs\": 10,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Simulate training.\n",
        "epochs = 10\n",
        "offset = random.random() / 5\n",
        "for epoch in range(2, epochs):\n",
        "    acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
        "    loss = 2**-epoch + random.random() / epoch + offset\n",
        "\n",
        "    # Log metrics to wandb.\n",
        "    run.log({\"acc\": acc, \"loss\": loss})\n",
        "\n",
        "# Finish the run and upload any remaining data.\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWgiJYh_NzS7"
      },
      "outputs": [],
      "source": [
        "# utils/data.py\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "from PIL import Image\n",
        "\n",
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        pixels = np.array(self.data.iloc[idx]['pixels'].split(), dtype='uint8').reshape(48, 48)\n",
        "        image = Image.fromarray(pixels)  # PIL Image\n",
        "        label = int(self.data.iloc[idx]['emotion']) if 'emotion' in self.data.columns else -1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_data_loaders(csv_path, batch_size=64):\n",
        "    # Define transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomCrop(48, padding=4),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    val_test_transform = transforms.ToTensor()\n",
        "\n",
        "    # Load the full dataset without a transform initially\n",
        "    dataset = FER2013Dataset(csv_file=csv_path, transform=None)\n",
        "\n",
        "    # Split into train/val/test\n",
        "    train_len = int(0.7 * len(dataset))\n",
        "    val_len = int(0.15 * len(dataset))\n",
        "    test_len = len(dataset) - train_len - val_len\n",
        "    train_data, val_data, test_data = random_split(dataset, [train_len, val_len, test_len])\n",
        "\n",
        "    # Manually assign transforms to each subset\n",
        "    train_data.dataset.transform = train_transform\n",
        "    val_data.dataset.transform = val_test_transform\n",
        "    test_data.dataset.transform = val_test_transform\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "uIBDCBYIYi5g"
      },
      "outputs": [],
      "source": [
        "# model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 256)\n",
        "        self.fc2 = nn.Linear(256, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 24x24\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 12x12\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # 6x6\n",
        "        x = x.view(-1, 256 * 6 * 6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PCydxf1nOdGS",
        "outputId": "e5fbc04f-3bdf-4acc-9b60-268da1023830"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_155122-duxvi60c</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/duxvi60c' target=\"_blank\">run_3</a></strong> to <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/duxvi60c' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/duxvi60c</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging: train_acc=0.2757265127388535, val_acc=0.34626103111936835, lr=0.001\n",
            "Epoch 1/10 | Train Loss: 1.7660, Train Acc: 0.2757 | Val Loss: 1.6533, Val Acc: 0.3463\n",
            "Logging: train_acc=0.3766421178343949, val_acc=0.4143056200650255, lr=0.001\n",
            "Epoch 2/10 | Train Loss: 1.5938, Train Acc: 0.3766 | Val Loss: 1.5145, Val Acc: 0.4143\n",
            "Logging: train_acc=0.42356687898089174, val_acc=0.4424059451927543, lr=0.001\n",
            "Epoch 3/10 | Train Loss: 1.4935, Train Acc: 0.4236 | Val Loss: 1.4421, Val Acc: 0.4424\n",
            "Logging: train_acc=0.459593949044586, val_acc=0.46307477937761266, lr=0.001\n",
            "Epoch 4/10 | Train Loss: 1.4091, Train Acc: 0.4596 | Val Loss: 1.3847, Val Acc: 0.4631\n",
            "Logging: train_acc=0.4850716560509554, val_acc=0.4909428704133767, lr=0.001\n",
            "Epoch 5/10 | Train Loss: 1.3336, Train Acc: 0.4851 | Val Loss: 1.3274, Val Acc: 0.4909\n",
            "Logging: train_acc=0.5286126592356688, val_acc=0.5006967022758941, lr=0.0005\n",
            "Epoch 6/10 | Train Loss: 1.2393, Train Acc: 0.5286 | Val Loss: 1.2961, Val Acc: 0.5007\n",
            "Logging: train_acc=0.5530453821656051, val_acc=0.5146307477937762, lr=0.0005\n",
            "Epoch 7/10 | Train Loss: 1.1838, Train Acc: 0.5530 | Val Loss: 1.2699, Val Acc: 0.5146\n",
            "Logging: train_acc=0.5659832802547771, val_acc=0.518578727357176, lr=0.0005\n",
            "Epoch 8/10 | Train Loss: 1.1461, Train Acc: 0.5660 | Val Loss: 1.2702, Val Acc: 0.5186\n",
            "Logging: train_acc=0.581906847133758, val_acc=0.5281003251277288, lr=0.0005\n",
            "Epoch 9/10 | Train Loss: 1.1003, Train Acc: 0.5819 | Val Loss: 1.2499, Val Acc: 0.5281\n",
            "Logging: train_acc=0.6023089171974523, val_acc=0.5315838365071992, lr=0.0005\n",
            "Epoch 10/10 | Train Loss: 1.0538, Train Acc: 0.6023 | Val Loss: 1.2459, Val Acc: 0.5316\n",
            "\n",
            "✅ Final Test Loss: 1.2518, Test Accuracy: 0.5245\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>█████▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▅▆▇▇███</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.0005</td></tr><tr><td>test_accuracy</td><td>0.5245</td></tr><tr><td>test_loss</td><td>1.25176</td></tr><tr><td>train_accuracy</td><td>0.60231</td></tr><tr><td>train_loss</td><td>1.05382</td></tr><tr><td>val_accuracy</td><td>0.53158</td></tr><tr><td>val_loss</td><td>1.24592</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run_3</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/duxvi60c' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/duxvi60c</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_155122-duxvi60c/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# train.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "\n",
        "def train_and_validate(csv_path, batch_size=64, lr=0.001, epochs=10):\n",
        "    wandb.init(project=\"facial-expression\", name=\"run_3\", config={\n",
        "        \"batch_size\": batch_size,\n",
        "        \"lr\": lr,\n",
        "        \"epochs\": epochs\n",
        "    }, reinit=True)\n",
        "    try:\n",
        "        config = wandb.config\n",
        "\n",
        "        train_loader, val_loader, test_loader = get_data_loaders(csv_path, config.batch_size)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = SimpleCNN().to(device)\n",
        "        wandb.watch(model, log=\"all\", log_freq=10)  # optional: logs gradients and parameters\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "        for epoch in range(config.epochs):\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss = 0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            train_loss_avg = train_loss / len(train_loader)\n",
        "            train_acc = correct / total\n",
        "            val_loss_avg = val_loss / len(val_loader)\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            print(f\"Logging: train_acc={train_acc}, val_acc={val_acc}, lr={scheduler.get_last_lr()[0]}\")\n",
        "\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"train_loss\": train_loss_avg,\n",
        "                \"train_accuracy\": train_acc,\n",
        "                \"val_loss\": val_loss_avg,\n",
        "                \"val_accuracy\": val_acc,\n",
        "                \"learning_rate\": scheduler.get_last_lr()[0]\n",
        "            })\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{config.epochs} | \"\n",
        "                  f\"Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "                  f\"Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "            scheduler.step()\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loss_avg = test_loss / len(test_loader)\n",
        "        test_acc = test_correct / test_total\n",
        "\n",
        "        print(f\"\\n✅ Final Test Loss: {test_loss_avg:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "        wandb.log({\n",
        "            \"test_loss\": test_loss_avg,\n",
        "            \"test_accuracy\": test_acc\n",
        "        })\n",
        "\n",
        "        # Save model\n",
        "        torch.save(model.state_dict(), \"model.pth\")\n",
        "        wandb.save(\"model.pth\")  # optional but recommended\n",
        "        artifact = wandb.Artifact('facial-expression-model', type='model')\n",
        "        artifact.add_file('model.pth')\n",
        "        wandb.log_artifact(artifact)\n",
        "    finally:\n",
        "        wandb.finish()\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_validate(\"train.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
