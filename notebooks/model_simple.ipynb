{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KPmUEiDU7rZ"
      },
      "source": [
        "# Downloading Data / Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq6LpnkmvOBq",
        "outputId": "0a3adaa6-1298-4310-be78-50f475f8b2cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4su2vqTv8ep",
        "outputId": "01722e37-79b5-4dac-fc51-86b9854a7716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TXMXE1V20I88"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T6wk8CKj10T2"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/kaggle_api_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IEOsIdUo208p"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaufNfIP3kvU",
        "outputId": "2d2f8daa-e5e1-47eb-9984-233d51a6b00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 91% 260M/285M [00:00<00:00, 365MB/s]\n",
            "100% 285M/285M [00:00<00:00, 363MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download challenges-in-representation-learning-facial-expression-recognition-challenge --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q57Qk0Ww9ZFy",
        "outputId": "ae5167c7-81dc-4c74-f7e5-9a0802b257b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 286M\n",
            "-rw-r--r-- 1 root root 286M Dec 11  2019 challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "drwx------ 6 root root 4.0K Jun  5 19:41 drive\n",
            "drwxr-xr-x 1 root root 4.0K Jun  4 21:29 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vb3YNjA-nv2",
        "outputId": "aeeb835f-0526-4ba3-a39f-4f46f2413e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF-EeCU-CEXm"
      },
      "source": [
        "# Set up Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q-TUAsoMCIO3"
      },
      "outputs": [],
      "source": [
        "!pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "U_iJer9FF7YC",
        "outputId": "3130acc6-bb5d-4feb-c024-871fbc393d27"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mashar-22\u001b[0m (\u001b[33mashar-22-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "YsUyaO-7Gs7u",
        "outputId": "963471dd-12b3-462d-db3e-6f6c8e4d54e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-totem-4</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/3ioiae4q' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/3ioiae4q</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_135717-3ioiae4q/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_135938-zl9j1cyl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">breezy-glitter-3</a></strong> to <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▁▆▇▄▆█</td></tr><tr><td>loss</td><td>█▄▂▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.84463</td></tr><tr><td>loss</td><td>0.2518</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">breezy-glitter-3</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup/runs/zl9j1cyl</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/setup</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_135938-zl9j1cyl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import wandb\n",
        "\n",
        "# Start a new wandb run to track this script.\n",
        "run = wandb.init(\n",
        "    # Set the wandb entity where your project will be logged (generally your team name).\n",
        "    entity=\"ashar-22-free-university-of-tbilisi-\",\n",
        "    # Set the wandb project where this run will be logged.\n",
        "    project=\"setup\",\n",
        "    # Track hyperparameters and run metadata.\n",
        "    config={\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"architecture\": \"CNN\",\n",
        "        \"dataset\": \"CIFAR-100\",\n",
        "        \"epochs\": 10,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Simulate training.\n",
        "epochs = 10\n",
        "offset = random.random() / 5\n",
        "for epoch in range(2, epochs):\n",
        "    acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
        "    loss = 2**-epoch + random.random() / epoch + offset\n",
        "\n",
        "    # Log metrics to wandb.\n",
        "    run.log({\"acc\": acc, \"loss\": loss})\n",
        "\n",
        "# Finish the run and upload any remaining data.\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wWgiJYh_NzS7"
      },
      "outputs": [],
      "source": [
        "# utils/data.py\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "from PIL import Image\n",
        "\n",
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = np.array(self.data.iloc[idx]['pixels'].split(), dtype='uint8').reshape(48, 48)\n",
        "        image = Image.fromarray(pixels)  # PIL Image\n",
        "        label = int(self.data.iloc[idx]['emotion']) if 'emotion' in self.data.columns else -1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_data_loaders(csv_path, batch_size=64):\n",
        "    # Define transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomCrop(48, padding=4),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    val_test_transform = transforms.ToTensor()\n",
        "\n",
        "    # Load the full dataset without a transform initially\n",
        "    dataset = FER2013Dataset(csv_file=csv_path, transform=None)\n",
        "\n",
        "    # Split into train/val/test\n",
        "    train_len = int(0.7 * len(dataset))\n",
        "    val_len = int(0.15 * len(dataset))\n",
        "    test_len = len(dataset) - train_len - val_len\n",
        "    train_data, val_data, test_data = random_split(dataset, [train_len, val_len, test_len])\n",
        "\n",
        "    # Manually assign transforms to each subset\n",
        "    train_data.dataset.transform = train_transform\n",
        "    val_data.dataset.transform = val_test_transform\n",
        "    test_data.dataset.transform = val_test_transform\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uIBDCBYIYi5g"
      },
      "outputs": [],
      "source": [
        "# model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 256)\n",
        "        self.fc2 = nn.Linear(256, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 24x24\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 12x12\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # 6x6\n",
        "        x = x.view(-1, 256 * 6 * 6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PCydxf1nOdGS",
        "outputId": "ef38b09d-a91f-426f-d1cd-04fb117cee85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_201449-z3savnbx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/z3savnbx' target=\"_blank\">run_3</a></strong> to <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/z3savnbx' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/z3savnbx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging: train_acc=0.28005573248407645, val_acc=0.3615884811890385, lr=0.001\n",
            "Epoch 1/10 | Train Loss: 1.7995, Train Acc: 0.2801 | Val Loss: 1.5811, Val Acc: 0.3616\n",
            "Logging: train_acc=0.4053045382165605, val_acc=0.40664189503019044, lr=0.001\n",
            "Epoch 2/10 | Train Loss: 1.5186, Train Acc: 0.4053 | Val Loss: 1.4965, Val Acc: 0.4066\n",
            "Logging: train_acc=0.4554637738853503, val_acc=0.4951230840687413, lr=0.001\n",
            "Epoch 3/10 | Train Loss: 1.3944, Train Acc: 0.4555 | Val Loss: 1.3099, Val Acc: 0.4951\n",
            "Logging: train_acc=0.47830414012738853, val_acc=0.4997677659080353, lr=0.001\n",
            "Epoch 4/10 | Train Loss: 1.3267, Train Acc: 0.4783 | Val Loss: 1.2787, Val Acc: 0.4998\n",
            "Logging: train_acc=0.5099024681528662, val_acc=0.5044124477473293, lr=0.001\n",
            "Epoch 5/10 | Train Loss: 1.2597, Train Acc: 0.5099 | Val Loss: 1.2624, Val Acc: 0.5044\n",
            "Logging: train_acc=0.5482683121019108, val_acc=0.532512772875058, lr=0.0005\n",
            "Epoch 6/10 | Train Loss: 1.1416, Train Acc: 0.5483 | Val Loss: 1.1956, Val Acc: 0.5325\n",
            "Logging: train_acc=0.5756867038216561, val_acc=0.5308871342313052, lr=0.0005\n",
            "Epoch 7/10 | Train Loss: 1.0788, Train Acc: 0.5757 | Val Loss: 1.2272, Val Acc: 0.5309\n",
            "Logging: train_acc=0.6040505573248408, val_acc=0.5522526706920576, lr=0.0005\n",
            "Epoch 8/10 | Train Loss: 1.0075, Train Acc: 0.6041 | Val Loss: 1.1967, Val Acc: 0.5523\n",
            "Logging: train_acc=0.6279359076433121, val_acc=0.557361820715281, lr=0.0005\n",
            "Epoch 9/10 | Train Loss: 0.9359, Train Acc: 0.6279 | Val Loss: 1.2205, Val Acc: 0.5574\n",
            "Logging: train_acc=0.6545083598726115, val_acc=0.5411054342777519, lr=0.0005\n",
            "Epoch 10/10 | Train Loss: 0.8662, Train Acc: 0.6545 | Val Loss: 1.3109, Val Acc: 0.5411\n",
            "\n",
            "✅ Final Test Loss: 1.3009, Test Accuracy: 0.5438\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>█████▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▆▆▇▇██▇</td></tr><tr><td>val_loss</td><td>█▆▃▃▂▁▂▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.0005</td></tr><tr><td>test_accuracy</td><td>0.54377</td></tr><tr><td>test_loss</td><td>1.30093</td></tr><tr><td>train_accuracy</td><td>0.65451</td></tr><tr><td>train_loss</td><td>0.86616</td></tr><tr><td>val_accuracy</td><td>0.54111</td></tr><tr><td>val_loss</td><td>1.31088</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run_3</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/z3savnbx' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/z3savnbx</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_201449-z3savnbx/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# train.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "\n",
        "def train_and_validate(csv_path, batch_size=64, lr=0.001, epochs=10):\n",
        "    wandb.init(project=\"facial-expression\", name=\"run_3\", config={\n",
        "        \"batch_size\": batch_size,\n",
        "        \"lr\": lr,\n",
        "        \"epochs\": epochs\n",
        "    }, reinit=True)\n",
        "    try:\n",
        "        config = wandb.config\n",
        "\n",
        "        train_loader, val_loader, test_loader = get_data_loaders(csv_path, config.batch_size)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = SimpleCNN().to(device)\n",
        "        wandb.watch(model, log=\"all\", log_freq=10)  # optional: logs gradients and parameters\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "        for epoch in range(config.epochs):\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss = 0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            train_loss_avg = train_loss / len(train_loader)\n",
        "            train_acc = correct / total\n",
        "            val_loss_avg = val_loss / len(val_loader)\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            print(f\"Logging: train_acc={train_acc}, val_acc={val_acc}, lr={scheduler.get_last_lr()[0]}\")\n",
        "\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"train_loss\": train_loss_avg,\n",
        "                \"train_accuracy\": train_acc,\n",
        "                \"val_loss\": val_loss_avg,\n",
        "                \"val_accuracy\": val_acc,\n",
        "                \"learning_rate\": scheduler.get_last_lr()[0]\n",
        "            })\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{config.epochs} | \"\n",
        "                  f\"Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "                  f\"Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "            scheduler.step()\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loss_avg = test_loss / len(test_loader)\n",
        "        test_acc = test_correct / test_total\n",
        "\n",
        "        print(f\"\\n✅ Final Test Loss: {test_loss_avg:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "        wandb.log({\n",
        "            \"test_loss\": test_loss_avg,\n",
        "            \"test_accuracy\": test_acc\n",
        "        })\n",
        "\n",
        "        # Save model\n",
        "        torch.save(model.state_dict(), \"model.pth\")\n",
        "        wandb.save(\"model.pth\")  # optional but recommended\n",
        "        artifact = wandb.Artifact('facial-expression-model', type='model')\n",
        "        artifact.add_file('model.pth')\n",
        "        wandb.log_artifact(artifact)\n",
        "    finally:\n",
        "        wandb.finish()\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_validate(\"train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utils/data.py\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "from PIL import Image\n",
        "\n",
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = np.array(self.data.iloc[idx]['pixels'].split(), dtype='uint8').reshape(48, 48)\n",
        "        image = Image.fromarray(pixels)  # PIL Image\n",
        "        label = int(self.data.iloc[idx]['emotion']) if 'emotion' in self.data.columns else -1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_data_loaders(csv_path, batch_size=64):\n",
        "    # Define transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomCrop(48, padding=4),\n",
        "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.25))\n",
        "    ])\n",
        "    val_test_transform = transforms.ToTensor()\n",
        "\n",
        "    # Load the full dataset without a transform initially\n",
        "    dataset = FER2013Dataset(csv_file=csv_path, transform=None)\n",
        "\n",
        "    # Split into train/val/test\n",
        "    train_len = int(0.7 * len(dataset))\n",
        "    val_len = int(0.15 * len(dataset))\n",
        "    test_len = len(dataset) - train_len - val_len\n",
        "    train_data, val_data, test_data = random_split(dataset, [train_len, val_len, test_len])\n",
        "\n",
        "    # Manually assign transforms to each subset\n",
        "    train_data.dataset.transform = train_transform\n",
        "    val_data.dataset.transform = val_test_transform\n",
        "    test_data.dataset.transform = val_test_transform\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ],
      "metadata": {
        "id": "dU3AiiFYzkLs"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 256)\n",
        "        self.fc2 = nn.Linear(256, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(-1, 256 * 6 * 6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "gb82IA2yzsni"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "\n",
        "def train_and_validate(csv_path, batch_size=64, lr=0.001, epochs=10):\n",
        "    wandb.init(project=\"facial-expression\", name=\"run_3\", config={\n",
        "        \"batch_size\": batch_size,\n",
        "        \"lr\": lr,\n",
        "        \"epochs\": epochs\n",
        "    }, reinit=True)\n",
        "    try:\n",
        "        config = wandb.config\n",
        "\n",
        "        train_loader, val_loader, test_loader = get_data_loaders(csv_path, config.batch_size)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = SimpleCNN().to(device)\n",
        "        wandb.watch(model, log=\"all\", log_freq=10)  # optional: logs gradients and parameters\n",
        "        # Adam optimizer with weight decay (L2 regularization)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "        # Criterion remains the same, e.g. CrossEntropyLoss\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Optional: learning rate scheduler\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                        factor=0.5, patience=2)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            train_loss = running_loss / total\n",
        "            train_acc = correct / total\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            val_loss /= val_total\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            # print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            # Step scheduler with validation loss\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_loss = 0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_loss_avg = test_loss / len(test_loader)\n",
        "        test_acc = test_correct / test_total\n",
        "\n",
        "        print(f\"\\n✅ Final Test Loss: {test_loss_avg:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "        wandb.log({\n",
        "            \"test_loss\": test_loss_avg,\n",
        "            \"test_accuracy\": test_acc\n",
        "        })\n",
        "\n",
        "        # Save model\n",
        "        torch.save(model.state_dict(), \"model.pth\")\n",
        "        wandb.save(\"model.pth\")  # optional but recommended\n",
        "        artifact = wandb.Artifact('facial-expression-model', type='model')\n",
        "        artifact.add_file('model.pth')\n",
        "        wandb.log_artifact(artifact)\n",
        "    finally:\n",
        "        wandb.finish()\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_validate(\"train.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "sjrxdH4bqsck",
        "outputId": "6ed8afc6-1f48-4374-d2ac-86e0eaeb28ce"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_203848-yesigdsk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/yesigdsk' target=\"_blank\">run_3</a></strong> to <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/yesigdsk' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/yesigdsk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run_3</strong> at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/yesigdsk' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression/runs/yesigdsk</a><br> View project at: <a href='https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression' target=\"_blank\">https://wandb.ai/ashar-22-free-university-of-tbilisi-/facial-expression</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_203848-yesigdsk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-6c4e10ea89c2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-6c4e10ea89c2>\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(csv_path, batch_size, lr, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}